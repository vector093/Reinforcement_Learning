{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6d2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9159718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SOFTWARE\\Anaconda3\\lib\\site-packages\\gym\\core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "D:\\SOFTWARE\\Anaconda3\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "numberOfActions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670f116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actionSpace = [0, 1, 2]\n",
    "numberOfStates = 20 ** 2\n",
    "GAMMA = 0.9\n",
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "294b078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBins():\n",
    "\n",
    "    bins = np.zeros((2, 20))\n",
    "    bins[0] = np.linspace(-1.20, 0.6, 20)\n",
    "    bins[1] = np.linspace(-0.07, 0.07, 20)\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa543096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignBins(observation, bins):\n",
    "    state = np.zeros(2)\n",
    "    for i in range(2):\n",
    "        state[i] = np.digitize(observation[i], bins[i])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fceb6d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    max_v = float('-inf')\n",
    "    for key, val in d.items():\n",
    "        if val > max_v:\n",
    "            max_v = val\n",
    "            max_key = key\n",
    "    return max_key, max_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d315c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initilizing the action value function\n",
    "def initQ():\n",
    "  Q = {}\n",
    "\n",
    "  for i in range(20):\n",
    "    for j in range(20):\n",
    "      Q[(i,j)] = {}\n",
    "      for action in range(env.action_space.n):\n",
    "        Q[(i,j)][action] = float(0)\n",
    "  return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c60c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initilize a random deterministic target policy\n",
    "def initTargetPolicy():\n",
    "  pi = {}\n",
    "\n",
    "  for i in range(20):\n",
    "    for j in range(20):\n",
    "      pi[(i,j)]= np.random.choice(actionSpace)\n",
    "  return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7c7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initReturns():\n",
    "    returns = {}\n",
    "    \n",
    "    for i in range(20):\n",
    "        for j in range(20):\n",
    "            returns[(i,j)] = {}\n",
    "            for action in range(env.action_space.n):\n",
    "                returns[(i,j)][action] = []\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4cb33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    max_v = float('-inf')\n",
    "    for key, val in d.items():\n",
    "        if val > max_v:\n",
    "            max_v = val\n",
    "            max_key = key\n",
    "    return max_key, max_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ad3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nStep_Tree_Backup(env, Q, bins, eps, n):\n",
    "    obs = env.reset()\n",
    "    state = tuple(assignBins(obs, bins))\n",
    "    if np.random.uniform() < eps:\n",
    "        action = env.action_space.sample()  # epsilon greedy\n",
    "    else:\n",
    "        action = max_dict(Q[state])[0]\n",
    "\n",
    "    count = 0\n",
    "    complete = 0\n",
    "    T = np.inf\n",
    "    t = 0\n",
    "\n",
    "    states = [state]\n",
    "    actions = [action]\n",
    "    rewards = [0]\n",
    "\n",
    "    for t in itertools.count():\n",
    "\n",
    "        if t < T:\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            count += 1\n",
    "\n",
    "            state = tuple(assignBins(obs, bins))\n",
    "            states.append(state)\n",
    "            rewards.append(reward)\n",
    "            if done:\n",
    "                T = t + 1\n",
    "\n",
    "                if count < 199:\n",
    "                    complete = 1\n",
    "                    #print('episode ends at step', t)\n",
    "            else:\n",
    "                if np.random.uniform() < eps:\n",
    "                    action = env.action_space.sample()  # epsilon greedy\n",
    "                else:\n",
    "                    action = max_dict(Q[state])[0]\n",
    "                actions.append(action)\n",
    "\n",
    "        tau = t - n + 1\n",
    "\n",
    "        if tau >= 0:\n",
    "            G = 0\n",
    "            if t + 1 >= T:\n",
    "                G = rewards[T]\n",
    "            else:\n",
    "                expected_q = 0\n",
    "                max_action, max_q = max_dict(Q[state])\n",
    "                greedy_actions = 0\n",
    "                for i in actionSpace:\n",
    "                    if Q[state][i] == max_q:\n",
    "                        greedy_actions += 1\n",
    "\n",
    "                non_greedy_action_probability = eps / len(actionSpace)\n",
    "                greedy_action_probability = ((1 - eps) / greedy_actions) + non_greedy_action_probability\n",
    "                for i in actionSpace:\n",
    "                    if Q[state][i] == max_q:\n",
    "                        expected_q += Q[state][i] * greedy_action_probability\n",
    "                    else:\n",
    "                        expected_q += Q[state][i] * non_greedy_action_probability\n",
    "                G = rewards[t + 1] + GAMMA * expected_q\n",
    "\n",
    "            for k in range(min(t, T - 1), tau + 1, -1):\n",
    "\n",
    "                state_k = states[k]\n",
    "                expected_q = 0\n",
    "                max_action, max_q = max_dict(Q[state_k])\n",
    "                greedy_actions = 0\n",
    "                for i in actionSpace:\n",
    "                    if Q[state_k][i] == max_q:\n",
    "                        greedy_actions += 1\n",
    "\n",
    "                non_greedy_action_probability = eps / len(actionSpace)\n",
    "                greedy_action_probability = ((1 - eps) / greedy_actions) + non_greedy_action_probability\n",
    "                for i in actionSpace:\n",
    "                    if Q[state_k][i] == max_q:\n",
    "                        expected_q += Q[state_k][i] * greedy_action_probability\n",
    "                    else:\n",
    "                        expected_q += Q[state_k][i] * non_greedy_action_probability\n",
    "\n",
    "                if actions[k] == max_action:\n",
    "                    G = rewards[k] + GAMMA * expected_q + GAMMA * greedy_action_probability * G\n",
    "                else:\n",
    "                    G = rewards[k] + GAMMA * expected_q + GAMMA * non_greedy_action_probability * G\n",
    "\n",
    "            state_action = (states[tau], actions[tau])\n",
    "            Q[state_action[0]][state_action[1]] += ALPHA * (G - Q[state_action[0]][state_action[1]])\n",
    "        # print('tau ', tau, '| Q %.2f' %  Q[states[tau]][actions[tau]], actions[tau])\n",
    "        if tau == T - 1:\n",
    "            break\n",
    "\n",
    "    return complete, np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60c93653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot_parameters(cumulative_completion, training_episodes):\n",
    "    title = f'total episodes vs completed episodes'\n",
    "    print(f'Evaluated {title}')\n",
    "    line, = plt.plot(\n",
    "        np.arange(1, training_episodes + 1),\n",
    "        cumulative_completion,\n",
    "        label=title)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "086fa1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = createBins()\n",
    "Q = initQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4c9b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "SARSA_completeList = []\n",
    "completed = 0\n",
    "eps = 0.05\n",
    "mem=0\n",
    "rewards = 0\n",
    "training_episodes = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f3af73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 100, and completed over past 100 episode 0\n",
      "i = 200, and completed over past 100 episode 0\n",
      "i = 300, and completed over past 100 episode 0\n",
      "i = 400, and completed over past 100 episode 3\n",
      "i = 500, and completed over past 100 episode 8\n",
      "i = 600, and completed over past 100 episode 11\n",
      "i = 700, and completed over past 100 episode 27\n",
      "i = 800, and completed over past 100 episode 26\n",
      "i = 900, and completed over past 100 episode 35\n",
      "i = 1000, and completed over past 100 episode 48\n",
      "i = 1100, and completed over past 100 episode 55\n",
      "i = 1200, and completed over past 100 episode 38\n",
      "i = 1300, and completed over past 100 episode 44\n",
      "i = 1400, and completed over past 100 episode 43\n",
      "i = 1500, and completed over past 100 episode 38\n",
      "i = 1600, and completed over past 100 episode 50\n",
      "i = 1700, and completed over past 100 episode 35\n",
      "i = 1800, and completed over past 100 episode 54\n",
      "i = 1900, and completed over past 100 episode 27\n",
      "i = 2000, and completed over past 100 episode 78\n",
      "i = 2100, and completed over past 100 episode 76\n",
      "i = 2200, and completed over past 100 episode 35\n",
      "i = 2300, and completed over past 100 episode 54\n",
      "i = 2400, and completed over past 100 episode 51\n",
      "i = 2500, and completed over past 100 episode 45\n",
      "i = 2600, and completed over past 100 episode 39\n",
      "i = 2700, and completed over past 100 episode 56\n",
      "i = 2800, and completed over past 100 episode 53\n",
      "i = 2900, and completed over past 100 episode 43\n",
      "i = 3000, and completed over past 100 episode 47\n",
      "i = 3100, and completed over past 100 episode 62\n",
      "i = 3200, and completed over past 100 episode 60\n",
      "i = 3300, and completed over past 100 episode 32\n",
      "i = 3400, and completed over past 100 episode 36\n",
      "i = 3500, and completed over past 100 episode 47\n",
      "i = 3600, and completed over past 100 episode 49\n",
      "i = 3700, and completed over past 100 episode 52\n",
      "i = 3800, and completed over past 100 episode 59\n",
      "i = 3900, and completed over past 100 episode 52\n",
      "i = 4000, and completed over past 100 episode 23\n",
      "i = 4100, and completed over past 100 episode 37\n",
      "i = 4200, and completed over past 100 episode 47\n",
      "i = 4300, and completed over past 100 episode 46\n",
      "i = 4400, and completed over past 100 episode 39\n",
      "i = 4500, and completed over past 100 episode 61\n",
      "i = 4600, and completed over past 100 episode 51\n",
      "i = 4700, and completed over past 100 episode 44\n",
      "i = 4800, and completed over past 100 episode 33\n",
      "i = 4900, and completed over past 100 episode 42\n",
      "Evaluated total episodes vs completed episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(training_episodes):\n",
    "    complete, reward = nStep_Tree_Backup(env, Q, bins, eps,3)\n",
    "    rewards += reward\n",
    "    completed += complete\n",
    "    if i % 100 == 0 and i != 0:\n",
    "        print(\"i = \" + str(i) + \", and completed over past 100 episode \" + str(completed - mem))\n",
    "        mem = completed\n",
    "        rewards = 0\n",
    "\n",
    "    SARSA_completeList.append(completed)\n",
    "\n",
    "evaluate_and_plot_parameters(SARSA_completeList, training_episodes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ff9620c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "eps = 0\n",
    "avg = 0\n",
    "for i in range(100):\n",
    "    complete,reward = nStep_Tree_Backup(env, Q, bins, eps,3)\n",
    "    avg += complete\n",
    "print(avg / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee8c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
